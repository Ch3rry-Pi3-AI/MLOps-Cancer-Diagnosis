name: deploy-prod

on:
  workflow_dispatch:
    inputs:
      confirm:
        description: "Type 'deploy' to confirm"
        required: true
        default: "deploy"

jobs:
  deploy:
    if: ${{ github.event.inputs.confirm == 'deploy' }}
    runs-on: ubuntu-latest
    env:
      AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
      AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
      BACKEND_RESOURCE_GROUP_NAME: ${{ secrets.BACKEND_RESOURCE_GROUP_NAME }}
      BACKEND_STORAGE_ACCOUNT_NAME: ${{ secrets.BACKEND_STORAGE_ACCOUNT_NAME }}
      BACKEND_CONTAINER_NAME: ${{ secrets.BACKEND_CONTAINER_NAME }}
      AML_TRAIN_IMAGE_TAG: "0.1.0"
      AML_COMPUTE_NAME: "cpu-cluster"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.5.7"

      - name: Azure login (Service Principal)
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Export ARM_* for Terraform (azapi)
        run: |
          echo "ARM_CLIENT_ID=$(echo '${{ secrets.AZURE_CREDENTIALS }}' | jq -r .clientId)" >> $GITHUB_ENV
          echo "ARM_CLIENT_SECRET=$(echo '${{ secrets.AZURE_CREDENTIALS }}' | jq -r .clientSecret)" >> $GITHUB_ENV
          echo "ARM_TENANT_ID=$(echo '${{ secrets.AZURE_CREDENTIALS }}' | jq -r .tenantId)" >> $GITHUB_ENV
          echo "ARM_SUBSCRIPTION_ID=$(echo '${{ secrets.AZURE_CREDENTIALS }}' | jq -r .subscriptionId)" >> $GITHUB_ENV

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install uv
        run: python -m pip install --upgrade uv

      - name: Install deps
        run: uv sync

      - name: Ensure backend (tfstate) exists
        shell: bash
        run: |
          set -euo pipefail
          RG="${BACKEND_RESOURCE_GROUP_NAME}"
          SA="${BACKEND_STORAGE_ACCOUNT_NAME}"
          if ! az group show --name "$RG" >/dev/null 2>&1; then
            echo "Creating backend RG/storage via terraform/00_backend"
            pushd terraform/00_backend
            terraform init -upgrade
            terraform apply -auto-approve \
              -var "backend_resource_group_name=$RG" \
              -var "storage_account_name=$SA" \
              -var "container_name=${BACKEND_CONTAINER_NAME:-tfstate}"
            terraform output -json > outputs.json
            popd
          else
            echo "Backend RG exists. Skipping backend creation."
          fi

      - name: Deploy infra
        run: uv run python scripts/deploy.py --skip-adf-run

      - name: Run ADF master pipeline and wait for gold data
        shell: bash
        run: |
          set -euo pipefail
          RG_NAME=$(jq -r '.resource_group_name.value' terraform/01_resource_group/outputs.json)
          ADF_NAME=$(jq -r '.data_factory_name.value' terraform/07_data_factory/outputs.json)
          ADF_PIPELINE=$(jq -r '.pipeline_name.value' terraform/14_adf_pipeline_master/outputs.json)
          STORAGE_NAME=$(jq -r '.storage_account_name.value' terraform/03_storage_account/outputs.json)
          STORAGE_KEY=$(jq -r '.storage_account_primary_access_key.value' terraform/03_storage_account/outputs.json)

          run_id=$(az datafactory pipeline create-run \
            --resource-group "$RG_NAME" \
            --factory-name "$ADF_NAME" \
            --name "$ADF_PIPELINE" \
            --query runId -o tsv)
          echo "ADF run id: $run_id"

          for i in {1..60}; do
            status=$(az datafactory pipeline-run show \
              --resource-group "$RG_NAME" \
              --factory-name "$ADF_NAME" \
              --run-id "$run_id" \
              --query status -o tsv)
            echo "ADF status: $status"
            if [[ "$status" == "Succeeded" ]]; then
              break
            fi
            if [[ "$status" == "Failed" || "$status" == "Cancelled" ]]; then
              echo "ADF pipeline failed: $status"
              exit 1
            fi
            sleep 30
          done

          found=0
          for i in {1..20}; do
            count=$(az storage fs file list \
              --account-name "$STORAGE_NAME" \
              --account-key "$STORAGE_KEY" \
              --file-system gold \
              --path breast_cancer/features \
              --query "length([?contains(name, '.parquet')])" -o tsv || echo 0)
            if [[ "${count:-0}" -gt 0 ]]; then
              found=1
              echo "Gold data present ($count parquet files)."
              break
            fi
            echo "Waiting for gold data..."
            sleep 15
          done

          if [[ "$found" -ne 1 ]]; then
            echo "Gold data not found after waiting."
            exit 1
          fi

      - name: Build/push train image (Docker)
        run: uv run python scripts/deploy.py --docker-build-train-image

      - name: Build/push inference image (Docker)
        run: uv run python scripts/deploy.py --docker-build-infer-image

      - name: Register AML pipeline component
        run: uv run python scripts/register_aml_assets.py --register-pipeline-component --pipeline-component-version ${{ github.run_number }}

      - name: Run AML pipeline
        run: uv run python scripts/run_pipeline_component.py --register-data-asset --component-version ${{ github.run_number }}
